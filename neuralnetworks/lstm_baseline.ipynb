{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset and split to train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamlcc\\datamining2\\venv\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Import datasets\n",
    "data_directory = './data/clean'\n",
    "X = pd.read_csv('{}/nn_X.csv'.format(data_directory), index_col=0)\n",
    "Y = pd.read_csv('{}/nn_Y.csv'.format(data_directory), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577352, 79)\n(1577352, 3)\nIndex(['key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'mainCategory',\n       'category', 'subCategory', 'releaseDate', 'date', 'price',\n       'is_eleventh', 'is_crazy_day', 'day_of_week', 'day_Friday',\n       'day_Monday', 'day_Saturday', 'day_Sunday', 'day_Thursday',\n       'day_Tuesday', 'day_Wednesday', 'days_since_release', 'price_diff',\n       'color_beige', 'color_blau', 'color_braun', 'color_gelb', 'color_gold',\n       'color_grau', 'color_gruen', 'color_khaki', 'color_lila',\n       'color_orange', 'color_pink', 'color_rosa', 'color_rot',\n       'color_schwarz', 'color_silber', 'color_tuerkis', 'color_weiss',\n       'brand_Asics', 'brand_Cinquestelle', 'brand_Converse', 'brand_Diadora',\n       'brand_Erima', 'brand_FREAM', 'brand_Hummel', 'brand_Jako',\n       'brand_Jordan', 'brand_KangaROOS', 'brand_Kempa', 'brand_Lotto',\n       'brand_Mizuno', 'brand_New Balance', 'brand_Nike', 'brand_Onitsuka',\n       'brand_PUMA', 'brand_Reebok', 'brand_Reusch', 'brand_Sells',\n       'brand_Sport2000', 'brand_Stance', 'brand_Uhlsport',\n       'brand_Under Armour', 'brand_adidas', 'maincat_1', 'maincat_9',\n       'maincat_15', 'cat_2', 'cat_7', 'cat_10', 'cat_16', 'cat_18', 'cat_24',\n       'cat_30', 'cat_33', 'cat_36', 'cat_37'],\n      dtype='object')\nIndex(['key', 'date', 'sales'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X.columns)\n",
    "print(Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "keys_dates = pd.DataFrame(X['key']).join(X['date']) # Store for future lookups\n",
    "drop_x_cols = ['key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'date', 'day_of_week', \n",
    "             'mainCategory', 'category', 'subCategory', 'releaseDate']\n",
    "drop_y_cols = ['key', 'date']\n",
    "X = X.drop(drop_x_cols, axis=1)\n",
    "Y = Y.drop(drop_y_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy to reshape for input\n",
    "X = X.as_matrix()\n",
    "Y = Y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to get data into (# samples, # timesteps, # variables)\n",
    "# Training data will be shape (12,824, 92, # variables)\n",
    "X_tr = X[0:92]\n",
    "X_tr = X_tr[np.newaxis, :, :]\n",
    "for i in range(1, X.shape[0] // 123):\n",
    "    temp_x = X[i*123:i*123+92]\n",
    "    temp_x = temp_x[np.newaxis, :, :]\n",
    "    X_tr = np.concatenate((X_tr, temp_x), axis=0)\n",
    "print(X_tr.shape)  # Check if shape is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Y values the same way\n",
    "Y_tr = Y[0:92]\n",
    "Y_tr = Y_tr[np.newaxis, :, :]\n",
    "for i in range(1, Y.shape[0]//123):\n",
    "    temp_y = Y[i*123:i*123+92]\n",
    "    temp_y = temp_y[np.newaxis, :, :]\n",
    "    Y_tr = np.concatenate((Y_tr, temp_y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed, LSTM\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 8 # Try to maximise memory per batch\n",
    "num_hidden = 32\n",
    "timesteps = X_tr.shape[1]\n",
    "input_dim = X_tr.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_hidden, input_shape=(timesteps, input_dim), dropout=0, return_sequences=True))\n",
    "# Output has shape (batch_size, timesteps, num_hidden), so we add a dense layer to make it (batch_size, timesteps, 1)\n",
    "model.add(TimeDistributed(Dense(1, activation='relu', kernel_initializer='random_uniform'))) # With ReLu activation to clamp minimum to 0\n",
    "# We can then compare predictions directly with Y of size (batch_size, timesteps, 1)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "callbacks_list = [EarlyStopping(monitor='loss', patience=5),\n",
    "                  ModelCheckpoint(filepath='rnn-lstm-best_v1.h5', monitor='loss', save_best_only=True)]\n",
    "# ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, verbose=1, mode='min', cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM; running this will take a while!\n",
    "history = model.fit(X_tr, Y_tr, batch_size=batch_size,\n",
    "                    callbacks=callbacks_list,\n",
    "                    epochs = num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and history for future reuse\n",
    "model.save('rnn-lstm_v1.h5')\n",
    "with open('rnn-lstm-history_v1', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
