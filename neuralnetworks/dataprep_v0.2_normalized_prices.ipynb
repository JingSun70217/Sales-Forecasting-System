{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Subset of Data with Product Changing in Price, and Normalized Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from measures import wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need normalized prices\n",
    "raw_data = pd.read_csv('./data/prices_standardized/data_v03b.csv')\n",
    "# what we want to have overwritten\n",
    "dataset_old = pd.read_csv('./data/clean/data_v0.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1866, 285)\n"
     ]
    }
   ],
   "source": [
    " # generating dataset in such a way that pipeline remains unchanged\n",
    " df0= dataset_old[dataset_old.columns[:11]] # 'key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'mainCategory', 'category', 'subCategory', 'stock', 'releaseDate'\n",
    " df1= raw_data[raw_data.columns[(len(raw_data.columns)-9-151) : (len(raw_data.columns)-9)]] # 151 days normalized prices\n",
    " df2= dataset_old[dataset_old.columns[162:285]] # 123 days sales data\n",
    " df3= raw_data[raw_data.columns[(len(raw_data.columns)-9) : (len(raw_data.columns)-8)]] # Boolean whether product changes in price\n",
    " df= pd.concat([df0,df1,df2,df3], axis=1, join_axes=[df0.index])\n",
    " ###\n",
    " # at the beginnging we only want to look at subset of products whose price changes over time\n",
    "dataset= df.loc[df['changes in price']==True] # this is the subset we'll be working with\n",
    "del dataset['changes in price']\n",
    "print(dataset.shape) # should be 1866*246\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'mainCategory',\n       'category', 'subCategory', 'stock',\n       ...\n       '2018-01-22_sales', '2018-01-23_sales', '2018-01-24_sales',\n       '2018-01-25_sales', '2018-01-26_sales', '2018-01-27_sales',\n       '2018-01-28_sales', '2018-01-29_sales', '2018-01-30_sales',\n       '2018-01-31_sales'],\n      dtype='object', length=285)\n"
     ]
    }
   ],
   "source": [
    "# Drop February price-columns\n",
    "dataset = wrangling.remove_price_cols(dataset, '2018-02-01', '2018-02-28')\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Y labels from X variables\n",
    "Y_dataset = wrangling.sales_cols(dataset, '2017-10-01', '2018-01-31') \n",
    "X_dataset = wrangling.remove_sales_cols(dataset, '2017-10-01', '2018-01-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'mainCategory',\n       'category', 'subCategory', 'releaseDate',\n       ...\n       '2018-02-19_prices_normalized', '2018-02-20_prices_normalized',\n       '2018-02-21_prices_normalized', '2018-02-22_prices_normalized',\n       '2018-02-23_prices_normalized', '2018-02-24_prices_normalized',\n       '2018-02-25_prices_normalized', '2018-02-26_prices_normalized',\n       '2018-02-27_prices_normalized', '2018-02-28_prices_normalized'],\n      dtype='object', length=161)\n"
     ]
    }
   ],
   "source": [
    "X_dataset = X_dataset.drop('stock', axis=1)\n",
    "print(X_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281766, 12)\n              key  pid_x size_x  color brand    rrp  mainCategory  category  \\\n281761  2286945,5  22869   45,5  weiss  Nike  95.18             1         2   \n281762  2286945,5  22869   45,5  weiss  Nike  95.18             1         2   \n281763  2286945,5  22869   45,5  weiss  Nike  95.18             1         2   \n281764  2286945,5  22869   45,5  weiss  Nike  95.18             1         2   \n281765  2286945,5  22869   45,5  weiss  Nike  95.18             1         2   \n\n        subCategory releaseDate                          date     price  \n281761          3.0  2017-10-01  2018-02-24_prices_normalized  0.325695  \n281762          3.0  2017-10-01  2018-02-25_prices_normalized -4.401747  \n281763          3.0  2017-10-01  2018-02-26_prices_normalized -4.401747  \n281764          3.0  2017-10-01  2018-02-27_prices_normalized -4.401747  \n281765          3.0  2017-10-01  2018-02-28_prices_normalized  0.325695  \n"
     ]
    }
   ],
   "source": [
    "# Flatten X so that each row is 1 day; we expect 12,824*123 = 1,577,352 rows as result\n",
    "cols = ['key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'mainCategory', 'category', 'subCategory', 'releaseDate']\n",
    "X_flat = pd.melt(X_dataset, id_vars=cols, var_name='date', value_name='price')\n",
    "X_flat = X_flat.sort_values(['key', 'date']).reset_index(drop=True)\n",
    "print(X_flat.shape)\n",
    "print(X_flat.tail()) # Quick check of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229518, 3)\n              key              date  sales\n229513  2286945,5  2018-01-27_sales    0.0\n229514  2286945,5  2018-01-28_sales    0.0\n229515  2286945,5  2018-01-29_sales    1.0\n229516  2286945,5  2018-01-30_sales    0.0\n229517  2286945,5  2018-01-31_sales    0.0\n"
     ]
    }
   ],
   "source": [
    "# Flatten Y similarly, so that the rows of Y correspond to that of X\n",
    "Y_flat = pd.melt(Y_dataset, id_vars='key', var_name='date', value_name='sales')\n",
    "Y_flat = Y_flat.sort_values(['key', 'date']).reset_index(drop=True)\n",
    "print(Y_flat.shape)\n",
    "print(Y_flat.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean 'date' columns to keep only YYYY-MM-DD part\n",
    "X_flat['date'] = X_flat['date'].str[0:10]\n",
    "Y_flat['date'] = Y_flat['date'].str[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat['subCategory'] = X_flat['subCategory'].fillna(0) # Fill blank sub-category with 0\n",
    "X_flat['size_x'] = X_flat['size_x'].fillna('NA') # Fill blank sizes with 'NA' string\n",
    "X_flat['price'] = X_flat['price'].fillna(method='bfill') # Fill blank prices with earliest given price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      key  pid_x size_x    color   brand    rrp  mainCategory  category  \\\n0  10013L  10013      L  schwarz  adidas  69.78             1         7   \n1  10013L  10013      L  schwarz  adidas  69.78             1         7   \n2  10013L  10013      L  schwarz  adidas  69.78             1         7   \n3  10013L  10013      L  schwarz  adidas  69.78             1         7   \n4  10013L  10013      L  schwarz  adidas  69.78             1         7   \n\n   subCategory releaseDate        date     price  \n0         16.0  2017-10-27  2017-10-01  0.260817  \n1         16.0  2017-10-27  2017-10-02  0.260817  \n2         16.0  2017-10-27  2017-10-03  0.260817  \n3         16.0  2017-10-27  2017-10-04  0.260817  \n4         16.0  2017-10-27  2017-10-05  0.260817  \n"
     ]
    }
   ],
   "source": [
    "print(X_flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_eleventh(row):\n",
    "    if row['date'][-2:] == '11':\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "X_flat['is_eleventh'] = X_flat.apply(is_eleventh, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_crazy_day(row):\n",
    "    if row['date'] == '2017-11-24': # Black Friday\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "X_flat['is_crazy_day'] = X_flat.apply(is_crazy_day, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding days\n",
    "def is_day(day):\n",
    "    if row['day_of_week'] == day:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "X_flat['day_of_week'] = pd.to_datetime(X_flat['date']).dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = pd.get_dummies(X_flat['day_of_week'], prefix='day')\n",
    "X_flat = X_flat.join(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat['days_since_release'] = (pd.to_datetime(X_flat['date']) - pd.to_datetime(X_flat['releaseDate'])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat['price_diff'] = X_flat['price'] - X_flat['rrp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding everything else except sub-category (too many of them)\n",
    "colors = pd.get_dummies(X_flat['color'], prefix='color')\n",
    "brands = pd.get_dummies(X_flat['brand'], prefix='brand')\n",
    "main_cats = pd.get_dummies(X_flat['mainCategory'], prefix='maincat')\n",
    "cats = pd.get_dummies(X_flat['category'], prefix='cat')\n",
    "sub_cats = pd.get_dummies(X_flat['subCategory'], prefix='subcat')\n",
    "\n",
    "X_flat = X_flat.join(colors)\n",
    "X_flat = X_flat.join(brands)\n",
    "X_flat = X_flat.join(main_cats)\n",
    "X_flat = X_flat.join(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'pid_x', 'size_x', 'color', 'brand', 'rrp', 'mainCategory',\n       'category', 'subCategory', 'releaseDate', 'date', 'price',\n       'is_eleventh', 'is_crazy_day', 'day_of_week', 'day_Friday',\n       'day_Monday', 'day_Saturday', 'day_Sunday', 'day_Thursday',\n       'day_Tuesday', 'day_Wednesday', 'days_since_release', 'price_diff',\n       'color_beige', 'color_blau', 'color_braun', 'color_gelb', 'color_gold',\n       'color_grau', 'color_gruen', 'color_khaki', 'color_lila',\n       'color_orange', 'color_pink', 'color_rosa', 'color_rot',\n       'color_schwarz', 'color_silber', 'color_tuerkis', 'color_weiss',\n       'brand_Asics', 'brand_Converse', 'brand_Erima', 'brand_Hummel',\n       'brand_Jako', 'brand_Jordan', 'brand_Kempa', 'brand_Lotto',\n       'brand_Mizuno', 'brand_New Balance', 'brand_Nike', 'brand_Onitsuka',\n       'brand_PUMA', 'brand_Reebok', 'brand_Reusch', 'brand_Sport2000',\n       'brand_Stance', 'brand_Uhlsport', 'brand_Under Armour', 'brand_adidas',\n       'maincat_1', 'maincat_9', 'maincat_15', 'cat_2', 'cat_7', 'cat_10',\n       'cat_16', 'cat_18', 'cat_24', 'cat_30', 'cat_33', 'cat_36', 'cat_37'],\n      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def marketing_activity(row):\n",
    "    marketingactivities=['2017-10-11','2017-10-16','2017-11-04','2017-11-11','2017-11-23','2017-11-24',\n",
    "                     '2017-11-25','2017-11-27','2017-12-03','2017-12-27','2017-12-28','2017-12-31',\n",
    "                    '2018-01-14','2018-01-22','2018-01-23','2018-01-30','2018-02-06','2018-02-07',\n",
    "                     '2018-02-20','2018-02-22','2018-02-23']\n",
    "    if row['date'] in marketingactivities:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_flat['marketing_activity'] = X_flat.apply(marketing_activity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store dataframes to csv\n",
    "import os\n",
    "out_directory = './data/clean'\n",
    "if not os.path.exists(out_directory): \n",
    "    os.makedirs(out_directory)\n",
    "\n",
    "X_flat.to_csv('{}/nn_X_normalized_prices.csv'.format(out_directory))\n",
    "Y_flat.to_csv('{}/nn_Y.csv_normalized_prices.csv'.format(out_directory))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
